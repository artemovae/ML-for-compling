{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Машинное обучение для лингвистов\n",
    "\n",
    "## Екатерина Черняк\n",
    "\n",
    "echernyak@hse.ru\n",
    "\n",
    "чат в телеграме для вопросов: https://t.me/joinchat/EVGQlkTn6X4UQXxqbCKIlQ\n",
    "\n",
    "Wiki-страница:  http://wiki.cs.hse.ru/Машинное_обучение_для_лингвистов\n",
    "\n",
    "репозиторий: https://github.com/echernyak/ML-for-compling\n",
    "\n",
    "канал в телеграме для объявлений: https://t.me/ml_for_compling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Кластеризация текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Постановка задачи\n",
    "\n",
    "* $d \\in D$ – документы\n",
    "* кластер – такая группа документов, что внутри группы документы *похожи* друг на друга, а два документа из разных групп друг на друга непохожи \n",
    "* $D$ требуется разбить на подмножества: $D = D_1 \\sqcup D_2 \\sqcup \\ldots \\sqcup D_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"clust_img/screen1.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"clust_img/berkeley_campus.png\" width=\"600\">\n",
    "\n",
    "Изображение: https://github.com/pksohn/tweet-clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"clust_img/screen2.jpg\" width=\"600\">\n",
    "\n",
    "Изображение: https://en.wikipedia.org/wiki/File:Self_oraganizing_map_cartography.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"clust_img/screen3.png\" width=\"600\">\n",
    "\n",
    "Изображение: https://github.com/d3/d3-hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"clust_img/screen4.png\" width=\"600\">\n",
    "\n",
    "Изображение: http://brandonrose.org/clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Представление документов для кластерного анализа \n",
    "\n",
    "\n",
    "Векторная модель: документ – вектор признаков \n",
    "\n",
    "* $d \\in D$ – документы\n",
    "* $w \\in V$ – словарь, всего слов |V|\n",
    "\n",
    "* традиционное представление: одно слово – одна размерность в векторной модели: $\\vec{d_i} = <f_1, ... , f_{|V|}>$\n",
    "* $f$ – компоненты вектора – могут быть:\n",
    "    * частотами\n",
    "    * $tf-idf$ весами\n",
    "* с использованием распределенных представлений слов [word embeddings]:\n",
    "    * покомпонентное среднее векторов слов, входящих в текст\n",
    "    * покомпонентный максимум векторов слов, входящих в текст\n",
    "* с использованием распределенных представлений слов [doc embeddings]:\n",
    "    * doc2vec\n",
    "    * fastText\n",
    "    * снижение размерности в векторной модели, в т. ч. сингулярное разложение [singular value decomposition, SVD]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Вычисление расстояния / близости между документами \n",
    "\n",
    "Евклидово расстояние: $ dist( \\vec{d_i}, \\vec{d_j}) = \\sqrt { \\sum_{k} ( d_i^k - d_j^k)^2 }$\n",
    "\n",
    "Косинусная мера близости: $ sim( \\vec{d_i}, \\vec{d_j}) =  \\cos(\\theta )=  \\frac{ \\vec{d_i}\\cdot \\vec{d_j} }{\\| \\vec{d_i} \\|_{2}\\|\\vec{d_j} \\|_{2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Алгоритмы кластерного анализа\n",
    "\n",
    "1. Иерархические алгоритмы [hierarchical algorithms] \n",
    "    * дивизимные алгоритмы [divisive / top down approach]\n",
    "    * аггломеративные алгоритмы [agglomerative / bottom up approach]\n",
    "2. Разделяющие алгоритмы [partitioning algorithms] \n",
    "    * Алгоритм k-средних [k-means algorithm]\n",
    "3. Спектральные алгоритмы [spectral clustering]\n",
    "4. Тематические модели как soft clustering [topic modelling]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Иерархические алгоритмы кластерного анализа\n",
    "\n",
    "\n",
    "<img src='http://www.statisticshowto.com/wp-content/uploads/2016/11/clustergram.png' align='right' style=\"margin-left:10px\"> \n",
    "\n",
    "* Дендрограма – дерево вложенных кластеров\n",
    "\n",
    "* Дивизимные алгоритмы строят дендрограму сверху вниз, аггломеративные – снизу вверх. \n",
    "\n",
    "* Не нужно задавать количество кластеров $K$\n",
    "\n",
    "* Плоские кластеры тоже можно получить, разрезав:\n",
    "    * все связи, имеющие значение сходства ниже заданного порога \n",
    "    * связи на $K$ первых уровнях \n",
    "\n",
    "\n",
    "\n",
    "Изображение: http://www.statisticshowto.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Аггломеративный алгоритм \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "&nbsp;\n",
    "* Каждый документ – отдельный кластер \n",
    "* Объединяем похожие документы в один кластер\n",
    "* Объединяем похожие кластеры в один кластер\n",
    "* Как вычислить сходство между документом и кластером? Кластером и кластером?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"clust_img/HAC.png\" width=\"500\" align='center'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Способы определения похожих кластеров\n",
    "\n",
    "<img src=\"clust_img/linkage.png\" width=\"500\" align='right'>\n",
    "\n",
    "* Single-link\n",
    "\n",
    "расстояние между двумя ближайшими точками из разных кластеров\n",
    "\n",
    "$sim(Cl_i, Cl_j) = \\max_{x \\in Cl_i, y \\in Cl_j}  sim(x,y)$\n",
    "\n",
    "* Complete-link\n",
    "\n",
    "расстояние между двумя наиболее удаленными точками из разных кластеров\n",
    "\n",
    "$sim(Cl_i, Cl_j) = \\min_{x \\in Cl_i, y \\in Cl_j}  sim(x,y)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "<img src=\"clust_img/linkage.png\" width=\"500\" align='right'>\n",
    "\n",
    "\n",
    "\n",
    "* Centroid-link\n",
    "\n",
    "расстояние между центроидами разных кластеров\n",
    "\n",
    "$sim(Cl_i, Cl_j) =   sim(c_i,c_j)$\n",
    "\n",
    "* Average-link\n",
    "\n",
    "$sim(Cl_i, Cl_j) =  \\frac{  \\sum_{x \\in Cl_i, y \\in Cl_j} sim(x,y) }{ |Cl_i \\cup Cl_j| (|Cl_i \\cup Cl_j| - 1)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "<img src=\"clust_img/SL_CL.png\" width=\"500\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Алгоритм k-средних\n",
    "\n",
    "<img src=\"https://www.mathworks.com/matlabcentral/mlc-downloads/downloads/submissions/24616/versions/14/screenshot.jpg\" width=\"400\" align='right'>\n",
    "\n",
    "\n",
    "\n",
    "* Разделение $D$ на $k$ кластеров\n",
    "* Кластеры формируются вокруг центроидов: $\\mu(Cl) = \\frac {1} {|Cl|} \\sum_{d \\in D} \\vec{d_i}$\n",
    "\n",
    "\n",
    "1. Выбрать $k$ случайных документов в качестве первоначальных центроидов $\\{s_1, ..., s_k\\}$\n",
    "\n",
    "2. Вокруг центроидов сформировать кластеры: $d_i$ относится к кластеру $Cl_j$, если расстояние $dist(d_i, s_j)$\n",
    "минимально\n",
    "\n",
    "3. Пересчитать центроиды кластеров: $s_j = \\mu(Cl_j)$\n",
    "\n",
    "4. Остановка алгоритма:\n",
    "    * центроиды не изменились (с точностью до $\\epsilon$)\n",
    "    * достигнуто максимальное количество итераций\n",
    "    * разбиение документов не изменилось \n",
    "    \n",
    "    \n",
    "demo: \n",
    "* http://syskall.com/kmeans.js/#\n",
    "* http://stanford.edu/class/ee103/visualizations/kmeans/kmeans.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Проблема выбора первоначальных центроидов\n",
    "\n",
    "<img src=\"clust_img/ClusterAnalysis_Mouse.png\" width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Алгоритм нормализованных сечений [normalized cuts] (алгоритм Ши-Малика)\n",
    "\n",
    "* $A$ – матрица близости документов \n",
    "* ${\\displaystyle L^{\\text{norm}}:=I-D^{-1/2}AD^{-1/2}}$ – матрица Лапласа, где $D_{ii} = \\sum_j A_{ij}$\n",
    "* $v$ – второй собственный вектор (соответствующий второму по величине собственному числу)\n",
    "* $m$ – медиана $v$ \n",
    "* В первый кластер помещают все документы, которым соответствуют значения вектора $v_i > m$, во второй – все остальные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Нормализованный разрез на графах\n",
    "<img src=\"clust_img/spec1.png\" width=\"600\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Примеры\n",
    "<img src=\"clust_img/spec2.png\" width=\"400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Меры качества кластеризации \n",
    "\n",
    "### Чистота [purity]\n",
    "\n",
    "* Допустим, что для каждого документа известен его истинный класс ($C_i$)\n",
    "* В каждом кластере $Cl_i$ найдем доминирующий (модальный) класс $C_j$\n",
    "\n",
    "$\\texttt{purity}(Cl_i) = \\frac{\\max_j n_{ij}}{n_i}$\n",
    "\n",
    "<img src=\"clust_img/purity.png\" width=\"400\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Rand Index \n",
    "\n",
    "|               | Общий кластер | Разные кластеры |\n",
    "|---------------|---------------|-----------------|\n",
    "| Общий класс   | A             | B               |\n",
    "| Разные классы | C             | D               |\n",
    "\n",
    "$RI = \\frac{A+D}{A+B+C+D}$ \n",
    "\n",
    "По аналогии с accuracy: доля объектов правильно отнесенных к одному кластеру"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Тематические модели для кластерного анализа\n",
    "\n",
    "\n",
    "<img src=\"clust_img/word2topic2doc.png\" width=\"200\" align='right'>\n",
    "\n",
    "Традиционная формулировка:\n",
    "* Тема – набор слов с вероятностями: $p(w|t)$\n",
    "* Документ – набор тем с вероятностями: $p(t|d)$\n",
    "\n",
    "$ p(w|d) = \\sum_{t \\in T} p(w|t) p(t|d)$\n",
    "\n",
    "Обратная формулировка:\n",
    "* Тема – множество документов, документ с определенной вероятностью принадлежит теме: $p(t|d)$\n",
    "\n",
    "В терминах кластерного анализа:\n",
    "* Тема – кластер, определена степень вхождения документа в каждый кластер: $p(t|d)$\n",
    "\n",
    "Латентное размещение Дирихле (Latent Dirichlet allocation) – самая распространенная тематическая модель "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Что почитать:\n",
    "    * IR Book, ch. 16, ch. 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
