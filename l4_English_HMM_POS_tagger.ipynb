{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "3914\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "train_data = treebank.tagged_sents()[:3500]\n",
    "test_data = treebank.tagged_sents()[3500:]\n",
    "print(train_data[0])\n",
    "print(len(treebank.tagged_sents()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# nltk.download('help/tagsets/PY3/upenn_tagset.pickle')\n",
    "# nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HiddenMarkovModelTagger 46 states and 11668 output symbols>\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import hmm\n",
    "trainer = hmm.HiddenMarkovModelTrainer()\n",
    "tagger = trainer.train_supervised(train_data)\n",
    "print(tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most probable transitions:\n",
      "SYM ---> NNP (log(p) = 0.0000)\n",
      "# ---> CD (log(p) = 0.0000)\n",
      "$ ---> CD (log(p) = -0.0166)\n",
      "PDT ---> DT (log(p) = -0.2016)\n",
      ". ---> '' (log(p) = -0.2224)\n",
      "WDT ---> -NONE- (log(p) = -0.2321)\n",
      "MD ---> VB (log(p) = -0.2987)\n",
      "WP ---> -NONE- (log(p) = -0.3735)\n",
      "RBS ---> JJ (log(p) = -0.4436)\n",
      "WP$ ---> NN (log(p) = -0.7370)\n",
      "EX ---> VBZ (log(p) = -0.7655)\n",
      "TO ---> VB (log(p) = -0.7941)\n",
      "VBN ---> -NONE- (log(p) = -0.8513)\n",
      "FW ---> VBZ (log(p) = -1.0000)\n",
      "DT ---> NN (log(p) = -1.0906)\n",
      "LS ---> -RRB- (log(p) = -1.1155)\n",
      "JJ ---> NN (log(p) = -1.1763)\n",
      "PRP$ ---> NN (log(p) = -1.2082)\n",
      "POS ---> NN (log(p) = -1.3209)\n",
      "NNP ---> NNP (log(p) = -1.3766)\n"
     ]
    }
   ],
   "source": [
    "nodes = tagger._states\n",
    "transitions = tagger._transitions_matrix()\n",
    "words = tagger._symbols\n",
    "priors = tagger._priors \n",
    "posteriors = tagger._outputs\n",
    "\n",
    "triples = [[nodes[j], nodes[i], transitions[i][j]]  for i in range(len(nodes)) for j in range(len(nodes))]\n",
    "triples.sort(key=lambda x: x[2], reverse=True)\n",
    "print('Most probable transitions:')\n",
    "for triple in triples[:20]:\n",
    "    print('{} ---> {} (log(p) = {:1.4f})'.format(*triple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most probable nouns:\n",
      "company (p = 0.0181)\n",
      "year (p = 0.0159)\n",
      "market (p = 0.0141)\n",
      "trading (p = 0.0115)\n",
      "stock (p = 0.0106)\n",
      "program (p = 0.0102)\n",
      "president (p = 0.0095)\n",
      "share (p = 0.0079)\n",
      "business (p = 0.0058)\n",
      "government (p = 0.0057)\n",
      "price (p = 0.0053)\n",
      "index (p = 0.0051)\n",
      "time (p = 0.0049)\n",
      "money (p = 0.0045)\n",
      "issue (p = 0.0045)\n",
      "yesterday (p = 0.0044)\n",
      "interest (p = 0.0043)\n",
      "investment (p = 0.0043)\n",
      "week (p = 0.0039)\n",
      "number (p = 0.0036)\n"
     ]
    }
   ],
   "source": [
    "print('Most probable nouns:')\n",
    "nouns = [[word, posteriors['NN'].prob(word)] for word in words if word.isalpha()]\n",
    "nouns.sort(key=lambda x: x[1], reverse=True)\n",
    "for noun in nouns[:20]:\n",
    "    print('{} (p = {:1.4f})'.format(*noun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most probable verbs:\n",
      "be (p = 0.1356)\n",
      "have (p = 0.0410)\n",
      "make (p = 0.0257)\n",
      "buy (p = 0.0188)\n",
      "take (p = 0.0157)\n",
      "get (p = 0.0157)\n",
      "help (p = 0.0140)\n",
      "do (p = 0.0135)\n",
      "sell (p = 0.0126)\n",
      "yield (p = 0.0122)\n",
      "pay (p = 0.0118)\n",
      "see (p = 0.0100)\n",
      "go (p = 0.0078)\n",
      "say (p = 0.0078)\n",
      "raise (p = 0.0074)\n",
      "keep (p = 0.0061)\n",
      "give (p = 0.0061)\n",
      "become (p = 0.0057)\n",
      "remain (p = 0.0052)\n",
      "want (p = 0.0052)\n"
     ]
    }
   ],
   "source": [
    "print('Most probable verbs:')\n",
    "nouns = [[word, posteriors['VB'].prob(word)] for word in words if word.isalpha()]\n",
    "nouns.sort(key=lambda x: x[1], reverse=True)\n",
    "for noun in nouns[:20]:\n",
    "    print('{} (p = {:1.4f})'.format(*noun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most probable POS tags for \"talks\":\n",
      "NNS (p = 0.0026)\n",
      "VBZ (p = 0.0010)\n"
     ]
    }
   ],
   "source": [
    "print('Most probable POS tags for \"talks\":')\n",
    "word = [[tag, posteriors[tag].prob('talks')] for tag in nodes]\n",
    "word.sort(key=lambda x: x[1], reverse=True)\n",
    "for w in word[:20]:\n",
    "    if w[1] > 0:\n",
    "        print('{} (p = {:1.4f})'.format(*w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Today', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('good', 'JJ'), ('day', 'NN'), ('.', '.')]\n",
      "[('Joe', 'NNP'), ('met', 'VBD'), ('Joanne', 'NNP'), ('in', 'IN'), ('Delhi', 'NNP'), ('.', 'NNP')]\n",
      "[('Chicago', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('birthplace', 'NNP'), ('of', 'NNP'), ('Ginny', 'NNP')]\n",
      "[('The', 'DT'), ('chief', 'NN'), ('talks', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "print(tagger.tag(\"Today is a good day .\".split()))\n",
    "\n",
    "print(tagger.tag(\"Joe met Joanne in Delhi .\".split()))\n",
    "\n",
    "print(tagger.tag(\"Chicago is the birthplace of Ginny\".split()))\n",
    "\n",
    "print(tagger.tag(\"The chief talks\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41872398102430053"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8777229160615742"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import tnt\n",
    "tnt_pos_tagger = tnt.TnT()\n",
    "tnt_pos_tagger.train(train_data)\n",
    "tnt_pos_tagger.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Today', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('good', 'JJ'), ('day', 'NN'), ('.', '.')]\n",
      "[('Joe', 'NNP'), ('met', 'VBD'), ('Joanne', 'NNP'), ('in', 'IN'), ('Delhi', 'Unk'), ('.', '.')]\n",
      "[('Chicago', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('birthplace', 'Unk'), ('of', 'IN'), ('Ginny', 'Unk')]\n",
      "[('The', 'DT'), ('chief', 'JJ'), ('talks', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "print(tnt_pos_tagger.tag(\"Today is a good day .\".split()))\n",
    "\n",
    "print(tnt_pos_tagger.tag(\"Joe met Joanne in Delhi .\".split()))\n",
    "\n",
    "print(tnt_pos_tagger.tag(\"Chicago is the birthplace of Ginny\".split()))\n",
    "\n",
    "print(tnt_pos_tagger.tag(\"The chief talks\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Задание\n",
    "\n",
    "Повторите аналогичные шаги на русскоязычных данных. Будем использовать данные из MorphoRuEval: возьмем размеченные предложения из Открытого корпуса, разделим их на две части, обучающую (30000 предложений) и тестовую (все остальное). \n",
    "\n",
    "Ссылка на файл с данными: https://github.com/dialogue-evaluation/morphoRuEval-2017/blob/master/OpenCorpora_Texts.rar\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_file = 'unamb_sent_14_6.conllu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "8508\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus.reader.conll import *\n",
    "train_reader = ConllCorpusReader(root = '', fileids = [train_file], columntypes = ['ignore', 'words', 'ignore', 'pos', 'chunk'])\n",
    "\n",
    "\n",
    "sents = list(train_reader.iob_sents())\n",
    "train_sents = sents[:30000]\n",
    "test_sents = sents[30000:]\n",
    "\n",
    "print(len(train_sents))\n",
    "print(len(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('«', 'PUNCT', '_'),\n",
       " ('Школа', 'NOUN', '_'),\n",
       " ('злословия', 'NOUN', '_'),\n",
       " ('»', 'PUNCT', '_'),\n",
       " ('учит', 'VERB', '_'),\n",
       " ('прикусить', 'VERB', '_'),\n",
       " ('язык', 'NOUN', '_')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
