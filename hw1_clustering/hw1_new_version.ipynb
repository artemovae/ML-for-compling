{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание 1 [10 баллов] \n",
    "# До 1.12.17 23:59\n",
    "\n",
    "Задание выполняется в группе (1-4 человека). В случае использования какого-либо строннего источника информации обязательно дайте на него ссылку (поскольку другие тоже могут на него наткнуться). Плагиат наказывается нулём баллов за задание и предвзятым отношением в будущем.\n",
    "\n",
    "Не все части обязательны для выполнения, однако вы можете быть дополнительно оштрафованы за небрежное за выполнение одной или двух частей вместо четырех.\n",
    "\n",
    "При возниконовении проблем с выполнением задания обращайтесь с вопросами к преподавателю. Поэтому настоятельно рекомендуется выполнять задание заранее, оставив запас времени на всевозможные технические проблемы. Если вы начали читать условие в последний вечер и не успели из-за проблем с установкой какой-либо библиотеки — это ваши проблемы.\n",
    "\n",
    "\n",
    "Результат выполнения задания — это отчёт в формате html на основе Jupyter Notebook. Нормальный отчёт должен включать в себя:\n",
    "* Краткую постановку задачи и формулировку задания\n",
    "* Описание **минимума** необходимой теории и/или описание используемых инструментов - не стоит переписывать лекции или Википедию\n",
    "* Подробный пошаговый рассказ о проделанной работе\n",
    "* Аккуратно оформленные результаты\n",
    "* **Внятные выводы** – не стоит относится к домашнему заданию как к последовательности сугубо технических шагов, а стоит относится скорее как к небольшому практическому исследованию, у которого есть своя цель и свое назначение.\n",
    "\n",
    "Небрежное его оформление отчета существенно отразится на итоговой оценке. Весь код из отчёта должен быть воспроизводимым, если для этого нужны какие-то дополнительные действия, установленные модули и т.п. — всё это должно быть прописано в тексте в явном виде.\n",
    "\n",
    "Сдача отчетов осуществляется через систему AnyTask.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# СЮДА надо теорию (если Амир не может, то мб Паша? Или я, но после среды тогда) нам нужно:\n",
    "* Задание выполнили: Бакаров Амир, Никишина Ирина, Степачев Павел (группа МКЛ171)\n",
    "* Краткую постановку задачи и формулировку задания\n",
    "* Описание **минимума** необходимой теории и/или описание используемых инструментов - не стоит переписывать лекции или Википедию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластеризация новостей\n",
    "Входная коллекция данных состоит из двух частей:\n",
    "1. events.csv – список 28 резонансных событий первой половины 2017 года, каждому событию присвоен свой порядковый номер (id)\n",
    "2. raw_news.csv – тексты новостей из различных новостных источников, известно, к какому резонансному событию относится каждая новость (столбец event_id).\n",
    "\n",
    "Будем считать, что одно событие – это один кластер. В этом домашнем задании вам предстоит:\n",
    "1. провести кластеризацию текстов новостей и проверить, получается ли восстановить кластерную структуру \n",
    "2. проверить, можно ли использовать кластерный анализ для обобщения: найти небольшое число кластеров и проверить, получается ли выделить общие направлени новостей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 1 [2 балла] Предварительная обработка текстов\n",
    "Проведите предобработку новостей: токенизацию, приведение к нижнему регистру, лемматизацию. Проверьте, есть ли в коллекции дубликаты. Посчитайте, сколько новостей относится к каждому резонансному событию. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импорт необходимых библиотек:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from os import path\n",
    "import glob\n",
    "import pickle\n",
    "import gensim\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from re import sub\n",
    "from pandas import DataFrame\n",
    "from pymystem3 import Mystem\n",
    "import texterra\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "import codecs\n",
    "import csv\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import *\n",
    "from sklearn.cluster import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import *\n",
    "import scipy.cluster.hierarchy as hac\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Было решено опробовать каждый из известных нам лемматизаторов (Mystem, pymorphy2 и Texterra) и понять, какой из них лучше работает для нашей задачи. \n",
    "\n",
    "Создаем экземпляры классов для каждого лемматизатора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = '9988cfb979b80264baeba1386cc7e455f99f943c'\n",
    "\n",
    "morph = MorphAnalyzer()\n",
    "m = Mystem()\n",
    "t = texterra.API(API_KEY)\n",
    "alpha_tokenizer = RegexpTokenizer('\\w+')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные из файлов 'events.csv' и 'raw_news.csv':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events = DataFrame.from_csv('events.csv')\n",
    "df_news = DataFrame.from_csv('raw_news.csv')\n",
    "texts = list(df_news.text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>В ПЕТЕРБУРГЕ ПРОШЕЛ МИТИНГ ПРОТИВ ПЕРЕДАЧИ ИС...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Lenta.co, Москва, 14 января 2017 СИТУАЦИЯ С П...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Аргументы и Факты (aif.ru), Москва, 14 января...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Google Новости ТОП, Москва, 14 января 2017 АК...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Газета.Ru, Москва, 13 января 2017 В МОСКОВСКО...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_id                                               text\n",
       "0         1   В ПЕТЕРБУРГЕ ПРОШЕЛ МИТИНГ ПРОТИВ ПЕРЕДАЧИ ИС...\n",
       "1         1   Lenta.co, Москва, 14 января 2017 СИТУАЦИЯ С П...\n",
       "2         1   Аргументы и Факты (aif.ru), Москва, 14 января...\n",
       "3         1   Google Новости ТОП, Москва, 14 января 2017 АК...\n",
       "4         1   Газета.Ru, Москва, 13 января 2017 В МОСКОВСКО..."
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько новостей относится к каждому резонансному событию?\n",
    "\n",
    "### Need graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17    102\n",
       "28    100\n",
       "18    100\n",
       "7     100\n",
       "10    100\n",
       "12    100\n",
       "27    100\n",
       "16    100\n",
       "1     100\n",
       "25    100\n",
       "26    100\n",
       "21    100\n",
       "23    100\n",
       "3      84\n",
       "22     82\n",
       "9      82\n",
       "24     62\n",
       "4      62\n",
       "2      51\n",
       "11     49\n",
       "19     45\n",
       "6      41\n",
       "8      27\n",
       "13     24\n",
       "20      8\n",
       "15      7\n",
       "5       2\n",
       "14      2\n",
       "Name: event_id, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.event_id.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть ли в коллекции дубликаты?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>9</td>\n",
       "      <td>Коммерсантъ. Новости информ. центра, Москва, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>9</td>\n",
       "      <td>Коммерсантъ. Новости информ. центра, Москва, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>9</td>\n",
       "      <td>Коммерсантъ. Новости информ. центра, Москва, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>9</td>\n",
       "      <td>Коммерсантъ. Новости информ. центра, Москва, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>9</td>\n",
       "      <td>Коммерсантъ. Новости информ. центра, Москва, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>9</td>\n",
       "      <td>Коммерсантъ. Новости информ. центра, Москва, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     event_id                                               text\n",
       "513         9   Коммерсантъ. Новости информ. центра, Москва, ...\n",
       "518         9   Коммерсантъ. Новости информ. центра, Москва, ...\n",
       "522         9   Коммерсантъ. Новости информ. центра, Москва, ...\n",
       "526         9   Коммерсантъ. Новости информ. центра, Москва, ...\n",
       "528         9   Коммерсантъ. Новости информ. центра, Москва, ...\n",
       "536         9   Коммерсантъ. Новости информ. центра, Москва, ..."
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news[df_news.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>В ПЕТЕРБУРГЕ ПРОШЕЛ МИТИНГ ПРОТИВ ПЕРЕДАЧИ ИС...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Lenta.co, Москва, 14 января 2017 СИТУАЦИЯ С П...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Аргументы и Факты (aif.ru), Москва, 14 января...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Google Новости ТОП, Москва, 14 января 2017 АК...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Газета.Ru, Москва, 13 января 2017 В МОСКОВСКО...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Top Real Estate (topre.ru), Москва, 13 января...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>Findnews.ru, Москва, 13 января 2017 ПОЛИЦИЯ Н...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>ПРАВДА.info (pravda.info), Москва, 13 января ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>Голос Америки (golos-ameriki.ru), Москва, 13 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Выбор Народа (vybor-naroda.org), Москва, 13 я...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>Flynews24.ru, Москва, 13 января 2017 @INTERFA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>Коммерсантъ. Новости Online, Москва, 13 январ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>Вести.ru, Москва, 13 января 2017 ПЕТЕРБУРЖЦЫ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>Findnews.ru, Москва, 13 января 2017 ПЕРЕД ИСА...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>Радио Свобода (svoboda.org), Москва, 13 январ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>ИА Regnum, Москва, 13 января 2017 ПЕРЕД ИСААК...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>Google Новости ТОП, Москва, 13 января 2017 ОП...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>Преступная Россия (crimerussia.com), Москва, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>Суть событий (argumentiru.com), Москва, 13 ян...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>Business FM (bfm.ru), Москва, 13 января 2017 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>Аргументы неделi (argumenti.ru), Москва, 13 я...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>Google Новости ТОП, Москва, 13 января 2017 TR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>The New Times (newtimes.ru), Москва, 13 январ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>Profi-news.ru, Москва, 13 января 2017 ПРОТИВН...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>Открытая Россия (openrussia.org), Москва, 13 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>РИА Новости, Москва, 13 января 2017 ПРОТИВНИК...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>Газета.Ru, Москва, 13 января 2017 АКЦИЯ ПРОТЕ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>Vistanews.ru, Москва, 13 января 2017 В ПЕТЕРБ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>Национальная Служба Новостей (nsn.fm), Москва...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>Ислам News (islamnews.ru), Москва, 13 января ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1900</th>\n",
       "      <td>28</td>\n",
       "      <td>ТАСС, Москва, 10 сентября 2017 ВСЕ КАНДИДАТЫ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1901</th>\n",
       "      <td>28</td>\n",
       "      <td>ТАСС, Москва, 10 сентября 2017 ВЫБОРЫ ГУБЕРНА...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>28</td>\n",
       "      <td>ТАСС, Москва, 10 сентября 2017 НА ВЫБОРАХ В С...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>28</td>\n",
       "      <td>ТАСС, Москва, 10 сентября 2017 МЕЖДУНАРОДНЫЕ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>28</td>\n",
       "      <td>ТАСС, Москва, 10 сентября 2017 ЭКСПЕРТЫ ОТМЕЧ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>28</td>\n",
       "      <td>ТАСС, Москва, 10 сентября 2017 МИНОБОРОНЫ: БО...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>28</td>\n",
       "      <td>Российская газета, Москва, 11 сентября 2017 П...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>28</td>\n",
       "      <td>Коммерсантъ (kommersant.ru), Москва, 10 сентя...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1908</th>\n",
       "      <td>28</td>\n",
       "      <td>Kp.ru, Москва, 10 сентября 2017 ВЫБОРЫ В МОСК...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1909</th>\n",
       "      <td>28</td>\n",
       "      <td>Kp.ru, Москва, 10 сентября 2017 ЖИТЕЛИ РАЙОНО...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1910</th>\n",
       "      <td>28</td>\n",
       "      <td>Московский Комсомолец, Москва, 11 сентября 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>28</td>\n",
       "      <td>РБК (rbc.ru), Москва, 10 сентября 2017 МОСГОР...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1912</th>\n",
       "      <td>28</td>\n",
       "      <td>РБК (rbc.ru), Москва, 10 сентября 2017 ПУТИН ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1913</th>\n",
       "      <td>28</td>\n",
       "      <td>РБК (rbc.ru), Москва, 10 сентября 2017 В РЕГИ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1914</th>\n",
       "      <td>28</td>\n",
       "      <td>РБК (rbc.ru), Москва, 10 сентября 2017 ГОЛОСО...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>28</td>\n",
       "      <td>Lenta.Ru, Москва, 10 сентября 2017 ПОЛИТОЛОГ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>28</td>\n",
       "      <td>Lenta.Ru, Москва, 10 сентября 2017 ИЗБИРАТЕЛЬ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>28</td>\n",
       "      <td>Lenta.Ru, Москва, 10 сентября 2017 НА ИЗБИРАТ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>28</td>\n",
       "      <td>Lenta.Ru, Москва, 10 сентября 2017 ГОЛОСОВАНИ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>28</td>\n",
       "      <td>Lenta.Ru, Москва, 10 сентября 2017 НАБЛЮДАТЕЛ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>28</td>\n",
       "      <td>Lenta.Ru, Москва, 10 сентября 2017 В БУРЯТИИ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>28</td>\n",
       "      <td>Lenta.Ru, Москва, 10 сентября 2017 ПУТИН ПРОГ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>28</td>\n",
       "      <td>Lenta.Ru, Москва, 10 сентября 2017 В МОСГОРИЗ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>28</td>\n",
       "      <td>Lenta.Ru, Москва, 10 сентября 2017 ЖИРИНОВСКИ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>28</td>\n",
       "      <td>Lenta.Ru, Москва, 10 сентября 2017 ЯВКА НА ВЫ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>28</td>\n",
       "      <td>Lenta.Ru, Москва, 10 сентября 2017 КАНДИДАТ В...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>28</td>\n",
       "      <td>Lenta.Ru, Москва, 10 сентября 2017 В ИЗБИРКОМ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>28</td>\n",
       "      <td>Lenta.Ru, Москва, 10 сентября 2017 КАНДИДАТ В...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>28</td>\n",
       "      <td>Lenta.Ru, Москва, 10 сентября 2017 МЕДВЕДЕВ П...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>28</td>\n",
       "      <td>Lenta.Ru, Москва, 10 сентября 2017 ЖИРИНОВСКИ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1924 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      event_id                                               text\n",
       "0            1   В ПЕТЕРБУРГЕ ПРОШЕЛ МИТИНГ ПРОТИВ ПЕРЕДАЧИ ИС...\n",
       "1            1   Lenta.co, Москва, 14 января 2017 СИТУАЦИЯ С П...\n",
       "2            1   Аргументы и Факты (aif.ru), Москва, 14 января...\n",
       "3            1   Google Новости ТОП, Москва, 14 января 2017 АК...\n",
       "4            1   Газета.Ru, Москва, 13 января 2017 В МОСКОВСКО...\n",
       "5            1   Top Real Estate (topre.ru), Москва, 13 января...\n",
       "6            1   Findnews.ru, Москва, 13 января 2017 ПОЛИЦИЯ Н...\n",
       "7            1   ПРАВДА.info (pravda.info), Москва, 13 января ...\n",
       "8            1   Голос Америки (golos-ameriki.ru), Москва, 13 ...\n",
       "9            1   Выбор Народа (vybor-naroda.org), Москва, 13 я...\n",
       "10           1   Flynews24.ru, Москва, 13 января 2017 @INTERFA...\n",
       "11           1   Коммерсантъ. Новости Online, Москва, 13 январ...\n",
       "12           1   Вести.ru, Москва, 13 января 2017 ПЕТЕРБУРЖЦЫ ...\n",
       "13           1   Findnews.ru, Москва, 13 января 2017 ПЕРЕД ИСА...\n",
       "14           1   Радио Свобода (svoboda.org), Москва, 13 январ...\n",
       "15           1   ИА Regnum, Москва, 13 января 2017 ПЕРЕД ИСААК...\n",
       "16           1   Google Новости ТОП, Москва, 13 января 2017 ОП...\n",
       "17           1   Преступная Россия (crimerussia.com), Москва, ...\n",
       "18           1   Суть событий (argumentiru.com), Москва, 13 ян...\n",
       "19           1   Business FM (bfm.ru), Москва, 13 января 2017 ...\n",
       "20           1   Аргументы неделi (argumenti.ru), Москва, 13 я...\n",
       "21           1   Google Новости ТОП, Москва, 13 января 2017 TR...\n",
       "22           1   The New Times (newtimes.ru), Москва, 13 январ...\n",
       "23           1   Profi-news.ru, Москва, 13 января 2017 ПРОТИВН...\n",
       "24           1   Открытая Россия (openrussia.org), Москва, 13 ...\n",
       "25           1   РИА Новости, Москва, 13 января 2017 ПРОТИВНИК...\n",
       "26           1   Газета.Ru, Москва, 13 января 2017 АКЦИЯ ПРОТЕ...\n",
       "27           1   Vistanews.ru, Москва, 13 января 2017 В ПЕТЕРБ...\n",
       "28           1   Национальная Служба Новостей (nsn.fm), Москва...\n",
       "29           1   Ислам News (islamnews.ru), Москва, 13 января ...\n",
       "...        ...                                                ...\n",
       "1900        28   ТАСС, Москва, 10 сентября 2017 ВСЕ КАНДИДАТЫ ...\n",
       "1901        28   ТАСС, Москва, 10 сентября 2017 ВЫБОРЫ ГУБЕРНА...\n",
       "1902        28   ТАСС, Москва, 10 сентября 2017 НА ВЫБОРАХ В С...\n",
       "1903        28   ТАСС, Москва, 10 сентября 2017 МЕЖДУНАРОДНЫЕ ...\n",
       "1904        28   ТАСС, Москва, 10 сентября 2017 ЭКСПЕРТЫ ОТМЕЧ...\n",
       "1905        28   ТАСС, Москва, 10 сентября 2017 МИНОБОРОНЫ: БО...\n",
       "1906        28   Российская газета, Москва, 11 сентября 2017 П...\n",
       "1907        28   Коммерсантъ (kommersant.ru), Москва, 10 сентя...\n",
       "1908        28   Kp.ru, Москва, 10 сентября 2017 ВЫБОРЫ В МОСК...\n",
       "1909        28   Kp.ru, Москва, 10 сентября 2017 ЖИТЕЛИ РАЙОНО...\n",
       "1910        28   Московский Комсомолец, Москва, 11 сентября 20...\n",
       "1911        28   РБК (rbc.ru), Москва, 10 сентября 2017 МОСГОР...\n",
       "1912        28   РБК (rbc.ru), Москва, 10 сентября 2017 ПУТИН ...\n",
       "1913        28   РБК (rbc.ru), Москва, 10 сентября 2017 В РЕГИ...\n",
       "1914        28   РБК (rbc.ru), Москва, 10 сентября 2017 ГОЛОСО...\n",
       "1915        28   Lenta.Ru, Москва, 10 сентября 2017 ПОЛИТОЛОГ ...\n",
       "1916        28   Lenta.Ru, Москва, 10 сентября 2017 ИЗБИРАТЕЛЬ...\n",
       "1917        28   Lenta.Ru, Москва, 10 сентября 2017 НА ИЗБИРАТ...\n",
       "1918        28   Lenta.Ru, Москва, 10 сентября 2017 ГОЛОСОВАНИ...\n",
       "1919        28   Lenta.Ru, Москва, 10 сентября 2017 НАБЛЮДАТЕЛ...\n",
       "1920        28   Lenta.Ru, Москва, 10 сентября 2017 В БУРЯТИИ ...\n",
       "1921        28   Lenta.Ru, Москва, 10 сентября 2017 ПУТИН ПРОГ...\n",
       "1922        28   Lenta.Ru, Москва, 10 сентября 2017 В МОСГОРИЗ...\n",
       "1923        28   Lenta.Ru, Москва, 10 сентября 2017 ЖИРИНОВСКИ...\n",
       "1924        28   Lenta.Ru, Москва, 10 сентября 2017 ЯВКА НА ВЫ...\n",
       "1925        28   Lenta.Ru, Москва, 10 сентября 2017 КАНДИДАТ В...\n",
       "1926        28   Lenta.Ru, Москва, 10 сентября 2017 В ИЗБИРКОМ...\n",
       "1927        28   Lenta.Ru, Москва, 10 сентября 2017 КАНДИДАТ В...\n",
       "1928        28   Lenta.Ru, Москва, 10 сентября 2017 МЕДВЕДЕВ П...\n",
       "1929        28   Lenta.Ru, Москва, 10 сентября 2017 ЖИРИНОВСКИ...\n",
       "\n",
       "[1924 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведите предобработку новостей: токенизацию, приведение к нижнему регистру, лемматизацию. Проверьте, есть ли в коллекции дубликаты. \n",
    "\n",
    "Лемматизация (и автоматические приведение к нижнему регистру). Мы решили рассмотреть три варианта лемматизации, поскольку не все способны одинаково хорошо справляться с контекстной омонимией (как, например, во фразе \"Запотело стекло. Варенье стекло по краю банки.\"):\n",
    "### Вы там что-то другое хотели вместо банок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_with_pymorphy(tokens):\n",
    "    return [morph.parse(word)[0].normal_form for word in tokens]\n",
    "\n",
    "def normalize_with_mystem(tokens):\n",
    "    return ''.join(m.lemmatize(' '.join(tokens))).split()\n",
    "\n",
    "def normalize_with_texterra(tokens):\n",
    "    time.sleep(10)\n",
    "    text = ' '.join(tokens)\n",
    "    return [token[3] for token in list(t.lemmatization(text))[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_type_of_tokens = {}\n",
    "tokenizers = {'pymorphy': normalize_with_pymorphy, 'texterra': normalize_with_texterra}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из-за того, что какждый раз данные лемматизировать слишком долго (особенно с Texterra), мы их преобразуем в поток байтов\n",
    "### Отсюда надо убрать фунцкии (или нет?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, tokenizer in tokenizers.items():\n",
    "    all_texts = []\n",
    "    for text in texts:\n",
    "        print(texts.index(text))\n",
    "        text = sub(r'http\\S+', '', text)\n",
    "        tokens = alpha_tokenizer.tokenize(text)\n",
    "        tokens = tokenizer(tokens)\n",
    "        all_texts.append(tokens)\n",
    "    print(all_texts)\n",
    "    with open('tokens_from_' + name + '.pickle', 'wb') as f:\n",
    "        pickle.dump(all_texts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мы попробовали всякие CountVectorizer, TF-IDF, но лучше всего отработали Word2Vec и Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do we need smth here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем наши леммы в словарь типа data = {'texterra' : [ [lemma1, lemma2 ...], [], [] ... [] ],  'mystem': [ ], etc.}:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for filename in glob.iglob(path.join(path.dirname(__file__),'lemmas_from_*.pickle'), recursive=True):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data_lemmas = pickle.load(f)\n",
    "        data[path.splitext(path.basename(filename))[0]] = data_lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Далее для каждого типа лемм создаем W2V модели, матрицу векторов для всех текстов, сохраняем ее в pickle:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем длину векторов для каждого слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_features = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name_of_alg, list_of_docs in data.items():\n",
    "    \n",
    "    model = gensim.models.Word2Vec(list_of_docs, size=num_of_features, min_count=30, window=30)\n",
    "    #model.save(name_of_alg.replace('lemmas','w2v_model2')+'.mdl')\n",
    "    \n",
    "    vectors_list = []\n",
    "    \n",
    "    for text_id in range(len(list_of_docs)):\n",
    "        vector_for_each_text = []\n",
    "        \n",
    "        for word in list_of_docs[text_id]:\n",
    "            try:\n",
    "                featureVec = np.zeros(shape=(1, num_of_features), dtype='float32')\n",
    "                featureVec = np.add(featureVec, model[word])\n",
    "                vector_for_each_text.append(featureVec)\n",
    "                \n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "        first_vector = np.array(vector_for_each_text[0])\n",
    "        for i in range(1, len(vector_for_each_text)):\n",
    "            first_vector = np.add(first_vector, vector_for_each_text[i])\n",
    "            \n",
    "        resultVec = np.divide(first_vector, len(vector_for_each_text))\n",
    "        vectors_list.append(resultVec)\n",
    "\n",
    "    vectors_array = np.array(vectors_list[0])\n",
    "    for i in range(1, len(vectors_list)):\n",
    "        vectors_array = np.vstack((vectors_array,vectors_list[i]))\n",
    "\n",
    "    with open(name_of_alg.replace('lemmas', 'vectors2')+ '.pickle', 'wb') as f:\n",
    "            pickle.dump(np.matrix(vectors_array), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То же самое происходит с Doc2Vec:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name_of_alg, list_of_docs in data.items():\n",
    "    \n",
    "    #тут короче преобразования для того, чтобы doc2vec нормально кушал тексты \n",
    "    sentences = [gensim.models.doc2vec.TaggedDocument(words=list_of_docs[doc], tags=[u'text']) for doc \n",
    "                 in range(len(list_of_docs))]\n",
    "    model = gensim.models.doc2vec.Doc2Vec(sentences, size=num_of_features, min_count=70, window=70)\n",
    "    #model.save(name_of_alg.replace('lemmas', 'd2v_model') + '.mdl')\n",
    "    model.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "\n",
    "\n",
    "    vectors_list = []\n",
    "    for text_id in range(len(list_of_docs)):\n",
    "        vector_for_each_text = []\n",
    "        for word in list_of_docs[text_id]:\n",
    "            try:\n",
    "                featureVec = np.zeros(shape=(1, num_of_features), dtype='float32')\n",
    "                featureVec = np.add(featureVec, model[word])\n",
    "                vector_for_each_text.append(featureVec)\n",
    "            except KeyError:\n",
    "                pass\n",
    "        first = np.array(vector_for_each_text[0])\n",
    "\n",
    "        for i in range(1, len(vector_for_each_text)):\n",
    "            first = np.add(first, vector_for_each_text[i])\n",
    "        resultVec = np.divide(first, len(vector_for_each_text))\n",
    "        vectors_list.append(resultVec)\n",
    "\n",
    "    vectors_array = np.array(vectors_list[0])\n",
    "\n",
    "    for i in range(1, len(vectors_list)):\n",
    "        vectors_array = np.vstack((vectors_array, vectors_list[i]))\n",
    "        \n",
    "    with open(name_of_alg.replace('lemmas', 'vectors_d2v') + '.pickle', 'wb') as f:\n",
    "            pickle.dump(np.matrix(vectors_array), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь самое приятное -- кластеризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Надо написать, что брали и почему...не знаю, почему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_alg = [KMeans, AgglomerativeClustering, SpectralClustering]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для отрисовки Agglomerative clustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotClusters(a):\n",
    "    z = hac.linkage(a, method='ward')\n",
    "    hac.dendrogram(z)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берем лэйблы из данных 'raw_news.csv':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(df_news.event_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь для каждого типа лемм применяем PipeLine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in glob.iglob('vectors_d2v_from_*.pickle', recursive=True):\n",
    "    with open(filename, 'rb') as f:\n",
    "        data_model = pickle.load(f)\n",
    "        \n",
    "        for alg in list_of_alg:\n",
    "            print(alg, filename.replace('vectors_d2v_from_', '').replace('.pickle',''))\n",
    "            \n",
    "            pipeline = Pipeline([('tfidf', TfidfTransformer()),\n",
    "                                 ('svd', TruncatedSVD(n_components=150)),\n",
    "                                 ('norm', Normalizer()),\n",
    "                                 ('clust', alg(n_clusters=28))\n",
    "                                ])\n",
    "            pipeline.fit(data_model)\n",
    "            \n",
    "            explained_variance = pipeline.named_steps['svd'].explained_variance_ratio_.sum()\n",
    "            print(\"Explained variance of the SVD step: {}%\".format(int(explained_variance * 100)))\n",
    "                        \n",
    "            clust_labels = pipeline.named_steps['clust'].labels_\n",
    "\n",
    "            print(\"Homogeneity:\", homogeneity_score(labels, clust_labels))\n",
    "            print(\"Completeness:\", completeness_score(labels, clust_labels))\n",
    "            print(\"V-measure\",  v_measure_score(labels, clust_labels))\n",
    "            print(\"Adjusted Rand-Index:\",  adjusted_rand_score(labels, clust_labels))\n",
    "            print(confusion_matrix(labels, clust_labels))\n",
    "            print('==============')\n",
    "        \n",
    "        if alg == AgglomerativeClustering:\n",
    "            plotClusters(data_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот тут вот сверху confusion matrix, если мы будем рисовать ее..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что-то..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
