{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')]\n",
      "3914\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "train_data = treebank.tagged_sents()[:3500]\n",
    "test_data = treebank.tagged_sents()[3500:]\n",
    "print(train_data[0])\n",
    "print(len(treebank.tagged_sents()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# nltk.download('help/tagsets/PY3/upenn_tagset.pickle')\n",
    "# nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HiddenMarkovModelTagger 14 states and 74479 output symbols>\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import hmm\n",
    "trainer = hmm.HiddenMarkovModelTrainer()\n",
    "tagger = trainer.train_supervised(train_data)\n",
    "print(tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most probable transitions:\n",
      "INTJ ---> PUNCT (log(p) = -0.2678)\n",
      "ADJ ---> NOUN (log(p) = -0.6067)\n",
      "NUM ---> NOUN (log(p) = -0.8638)\n",
      "ADP ---> NOUN (log(p) = -1.0095)\n",
      "DET ---> NOUN (log(p) = -1.0149)\n",
      "X ---> PUNCT (log(p) = -1.1769)\n",
      "PART ---> VERB (log(p) = -1.3060)\n",
      "PROPN ---> PUNCT (log(p) = -1.3316)\n",
      "PRON ---> VERB (log(p) = -1.3664)\n",
      "NOUN ---> PUNCT (log(p) = -1.5516)\n",
      "NUM ---> PUNCT (log(p) = -1.6549)\n",
      "ADV ---> VERB (log(p) = -1.7225)\n",
      "CONJ ---> NOUN (log(p) = -2.0315)\n",
      "X ---> X (log(p) = -2.2559)\n",
      "VERB ---> NOUN (log(p) = -2.2861)\n",
      "VERB ---> ADP (log(p) = -2.4043)\n",
      "ADP ---> ADJ (log(p) = -2.4953)\n",
      "VERB ---> PUNCT (log(p) = -2.5101)\n",
      "ADV ---> PUNCT (log(p) = -2.5800)\n",
      "NOUN ---> NOUN (log(p) = -2.6034)\n"
     ]
    }
   ],
   "source": [
    "nodes = tagger._states\n",
    "transitions = tagger._transitions_matrix()\n",
    "words = tagger._symbols\n",
    "priors = tagger._priors \n",
    "posteriors = tagger._outputs\n",
    "\n",
    "triples = [[nodes[j], nodes[i], transitions[i][j]]  for i in range(len(nodes)) for j in range(len(nodes))]\n",
    "triples.sort(key=lambda x: x[2], reverse=True)\n",
    "print('Most probable transitions:')\n",
    "for triple in triples[:20]:\n",
    "    print('{} ---> {} (log(p) = {:1.4f})'.format(*triple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('Most probable nouns:')\n",
    "nouns = [[word, posteriors['NN'].prob(word)] for word in words if word.isalpha()]\n",
    "nouns.sort(key=lambda x: x[1], reverse=True)\n",
    "for noun in nouns[:20]:\n",
    "    print('{} (p = {:1.4f})'.format(*noun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('Most probable verbs:')\n",
    "verbs = [[word, posteriors['VB'].prob(word)] for word in words if word.isalpha()]\n",
    "verbs.sort(key=lambda x: x[1], reverse=True)\n",
    "for verb in verbs[:20]:\n",
    "    print('{} (p = {:1.4f})'.format(*verb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most probable POS tags for \"talks\":\n"
     ]
    }
   ],
   "source": [
    "print('Most probable POS tags for \"talks\":')\n",
    "word = [[tag, posteriors[tag].prob('talks')] for tag in nodes]\n",
    "word.sort(key=lambda x: x[1], reverse=True)\n",
    "for w in word[:20]:\n",
    "    if w[1] > 0:\n",
    "        print('{} (p = {:1.4f})'.format(*w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Today', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('good', 'JJ'), ('day', 'NN'), ('.', '.')]\n",
      "[('Joe', 'NNP'), ('met', 'VBD'), ('Joanne', 'NNP'), ('in', 'IN'), ('Delhi', 'NNP'), ('.', 'NNP')]\n",
      "[('Chicago', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('birthplace', 'NNP'), ('of', 'NNP'), ('Ginny', 'NNP')]\n",
      "[('The', 'DT'), ('chief', 'NN'), ('talks', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "print(tagger.tag(\"Today is a good day .\".split()))\n",
    "\n",
    "print(tagger.tag(\"Joe met Joanne in Delhi .\".split()))\n",
    "\n",
    "print(tagger.tag(\"Chicago is the birthplace of Ginny\".split()))\n",
    "\n",
    "print(tagger.tag(\"The chief talks\".split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41872398102430053"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8777229160615742"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import tnt\n",
    "tnt_pos_tagger = tnt.TnT()\n",
    "tnt_pos_tagger.train(train_data)\n",
    "tnt_pos_tagger.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Today', 'NN'), ('is', 'VBZ'), ('a', 'DT'), ('good', 'JJ'), ('day', 'NN'), ('.', '.')]\n",
      "[('Joe', 'NNP'), ('met', 'VBD'), ('Joanne', 'NNP'), ('in', 'IN'), ('Delhi', 'Unk'), ('.', '.')]\n",
      "[('Chicago', 'NNP'), ('is', 'VBZ'), ('the', 'DT'), ('birthplace', 'Unk'), ('of', 'IN'), ('Ginny', 'Unk')]\n",
      "[('The', 'DT'), ('chief', 'JJ'), ('talks', 'NNS')]\n"
     ]
    }
   ],
   "source": [
    "print(tnt_pos_tagger.tag(\"Today is a good day .\".split()))\n",
    "\n",
    "print(tnt_pos_tagger.tag(\"Joe met Joanne in Delhi .\".split()))\n",
    "\n",
    "print(tnt_pos_tagger.tag(\"Chicago is the birthplace of Ginny\".split()))\n",
    "\n",
    "print(tnt_pos_tagger.tag(\"The chief talks\".split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Задание\n",
    "\n",
    "Повторите аналогичные шаги на русскоязычных данных. Будем использовать данные из MorphoRuEval: возьмем размеченные предложения из Открытого корпуса, разделим их на две части, обучающую (30000 предложений) и тестовую (все остальное). \n",
    "\n",
    "Ссылка на файл с данными: https://github.com/dialogue-evaluation/morphoRuEval-2017/blob/master/OpenCorpora_Texts.rar\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_file = 'unamb_sent_14_6.conllu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "8508\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus.reader.conll import *\n",
    "train_reader = ConllCorpusReader(root = '', fileids = [train_file], columntypes = ['ignore', 'words', 'ignore', 'pos', 'chunk'])\n",
    "\n",
    "\n",
    "sents = list(train_reader.iob_sents())\n",
    "train_sents = sents[:30000]\n",
    "test_sents = sents[30000:]\n",
    "\n",
    "print(len(train_sents))\n",
    "print(len(test_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('«', 'PUNCT', '_'),\n",
       " ('Школа', 'NOUN', '_'),\n",
       " ('злословия', 'NOUN', '_'),\n",
       " ('»', 'PUNCT', '_'),\n",
       " ('учит', 'VERB', '_'),\n",
       " ('прикусить', 'VERB', '_'),\n",
       " ('язык', 'NOUN', '_')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HiddenMarkovModelTagger 14 states and 74479 output symbols>\n",
      "Most probable transitions:\n",
      "INTJ ---> PUNCT (log(p) = -0.2678)\n",
      "ADJ ---> NOUN (log(p) = -0.6067)\n",
      "NUM ---> NOUN (log(p) = -0.8638)\n",
      "ADP ---> NOUN (log(p) = -1.0095)\n",
      "DET ---> NOUN (log(p) = -1.0149)\n",
      "X ---> PUNCT (log(p) = -1.1769)\n",
      "PART ---> VERB (log(p) = -1.3060)\n",
      "PROPN ---> PUNCT (log(p) = -1.3316)\n",
      "PRON ---> VERB (log(p) = -1.3664)\n",
      "NOUN ---> PUNCT (log(p) = -1.5516)\n",
      "NUM ---> PUNCT (log(p) = -1.6549)\n",
      "ADV ---> VERB (log(p) = -1.7225)\n",
      "CONJ ---> NOUN (log(p) = -2.0315)\n",
      "X ---> X (log(p) = -2.2559)\n",
      "VERB ---> NOUN (log(p) = -2.2861)\n",
      "VERB ---> ADP (log(p) = -2.4043)\n",
      "ADP ---> ADJ (log(p) = -2.4953)\n",
      "VERB ---> PUNCT (log(p) = -2.5101)\n",
      "ADV ---> PUNCT (log(p) = -2.5800)\n",
      "NOUN ---> NOUN (log(p) = -2.6034)\n"
     ]
    }
   ],
   "source": [
    "from nltk.tag import hmm\n",
    "trainer = hmm.HiddenMarkovModelTrainer()\n",
    "tagger = trainer.train_supervised(train_sents)\n",
    "print(tagger)\n",
    "\n",
    "nodes = tagger._states\n",
    "transitions = tagger._transitions_matrix()\n",
    "words = tagger._symbols\n",
    "priors = tagger._priors \n",
    "posteriors = tagger._outputs\n",
    "\n",
    "triples = [[nodes[j], nodes[i], transitions[i][j]]  for i in range(len(nodes)) for j in range(len(nodes))]\n",
    "triples.sort(key=lambda x: x[2], reverse=True)\n",
    "print('Most probable transitions:')\n",
    "for triple in triples[:20]:\n",
    "    print('{} ---> {} (log(p) = {:1.4f})'.format(*triple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most probable nouns:\n",
      "года (p = 0.0087)\n",
      "году (p = 0.0070)\n",
      "время (p = 0.0043)\n",
      "лет (p = 0.0039)\n",
      "Статья (p = 0.0037)\n",
      "человек (p = 0.0023)\n",
      "страны (p = 0.0017)\n",
      "год (p = 0.0017)\n",
      "Федерации (p = 0.0017)\n",
      "день (p = 0.0016)\n",
      "жизни (p = 0.0016)\n",
      "место (p = 0.0015)\n",
      "долларов (p = 0.0015)\n",
      "области (p = 0.0014)\n",
      "вопрос (p = 0.0014)\n",
      "числе (p = 0.0014)\n",
      "времени (p = 0.0014)\n",
      "власти (p = 0.0013)\n",
      "мира (p = 0.0013)\n",
      "млн (p = 0.0013)\n"
     ]
    }
   ],
   "source": [
    "print('Most probable nouns:')\n",
    "nouns = [[word, posteriors['NOUN'].prob(word)] for word in words if word.isalpha()]\n",
    "nouns.sort(key=lambda x: x[1], reverse=True)\n",
    "for noun in nouns[:20]:\n",
    "    print('{} (p = {:1.4f})'.format(*noun))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most probable verbs:\n",
      "был (p = 0.0176)\n",
      "будет (p = 0.0144)\n",
      "было (p = 0.0116)\n",
      "может (p = 0.0101)\n",
      "быть (p = 0.0100)\n",
      "были (p = 0.0100)\n",
      "была (p = 0.0094)\n",
      "является (p = 0.0067)\n",
      "могут (p = 0.0055)\n",
      "будут (p = 0.0051)\n",
      "стал (p = 0.0051)\n",
      "сказал (p = 0.0049)\n",
      "нет (p = 0.0037)\n",
      "заявил (p = 0.0033)\n",
      "имеет (p = 0.0032)\n",
      "стала (p = 0.0029)\n",
      "сообщает (p = 0.0029)\n",
      "стали (p = 0.0024)\n",
      "являются (p = 0.0022)\n",
      "говорит (p = 0.0022)\n"
     ]
    }
   ],
   "source": [
    "print('Most probable verbs:')\n",
    "verbs = [[word, posteriors['VERB'].prob(word)] for word in words if word.isalpha()]\n",
    "verbs.sort(key=lambda x: x[1], reverse=True)\n",
    "for verb in verbs[:20]:\n",
    "    print('{} (p = {:1.4f})'.format(*verb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most probable POS tags for \"стали\":\n",
      "VERB (p = 0.0024)\n",
      "NOUN (p = 0.0000)\n"
     ]
    }
   ],
   "source": [
    "print('Most probable POS tags for \"стали\":')\n",
    "word = [[tag, posteriors[tag].prob('стали')] for tag in nodes]\n",
    "word.sort(key=lambda x: x[1], reverse=True)\n",
    "for w in word[:20]:\n",
    "    if w[1] > 0:\n",
    "        print('{} (p = {:1.4f})'.format(*w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_sents_1 = []\n",
    "for sent in test_sents:\n",
    "    sent_1 = []\n",
    "    for word in sent:\n",
    "        sent_1.append(word[:2])\n",
    "    test_sents_1.append(sent_1)\n",
    "test_sents_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47075232194907907"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "tagger.evaluate(test_sents_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9953090882497362"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import tnt\n",
    "train_sents_1 = []\n",
    "for sent in test_sents:\n",
    "    sent_1 = []\n",
    "    for word in sent:\n",
    "        sent_1.append(word[:2])\n",
    "    train_sents_1.append(sent_1)\n",
    "test_sents_1[0]\n",
    "tnt_pos_tagger = tnt.TnT()\n",
    "tnt_pos_tagger.train(train_sents_1)\n",
    "tnt_pos_tagger.evaluate(test_sents_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
